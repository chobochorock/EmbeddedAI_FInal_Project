{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9a20e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model : ./best.pt\n",
      "Applying Pruning : (Ratio : 25.0%)\n",
      "64 layers applied!\n",
      "Applying Quantization and exporting onnx\n",
      "Ultralytics 8.3.235  Python-3.12.10 torch-2.10.0a0+rocm7.10.0a20251106 CUDA:1 (AMD Radeon RX 7800 XT, 16368MiB)\n",
      "Model summary (fused): 72 layers, 4,765,733 parameters, 0 gradients\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'best.pt' with input shape (1, 3, 128, 128) BCHW and output shape(s) (1, 4807, 336) (18.5 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.19.1 opset 11...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.78...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  7.1s, saved as 'best.onnx' (9.2 MB)\n",
      "\n",
      "Export complete (10.7s)\n",
      "Results saved to \u001b[1mC:\\Users\\garli\\Downloads\\yolo\u001b[0m\n",
      "Predict:         yolo predict task=detect model=best.onnx imgsz=128 half \n",
      "Validate:        yolo val task=detect model=best.onnx imgsz=128 data=data.yaml half \n",
      "Visualize:       https://netron.app\n",
      "------------------------------\n",
      "Exportation complete : best.onnx\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "import numpy as np\n",
    "from onnx import numpy_helper\n",
    "from onnxconverter_common import float16\n",
    "import copy\n",
    "\n",
    "def sparsify_onnx_weights(model, k):\n",
    "    \"\"\"\n",
    "    AID_Pruning_Exercise.ipynb의 'sparsify_by_weights' 로직을 ONNX에 적용.\n",
    "    가중치의 절대값 크기가 작은 하위 k(비율)만큼을 0으로 만듭니다.\n",
    "    \"\"\"\n",
    "    print(f\"Applying Weight Pruning (Sparsity: {k})...\")\n",
    "    \n",
    "    # 모델의 모든 초기화 값(Weights, Biases 등)을 순회\n",
    "    # ONNX에서 가중치는 graph.initializer에 저장됩니다.\n",
    "    total_weights = len(model.graph.initializer)\n",
    "    \n",
    "    for idx, tensor in enumerate(model.graph.initializer):\n",
    "        # ONNX Tensor를 Numpy 배열로 변환\n",
    "        weight_array = numpy_helper.to_array(tensor)\n",
    "        \n",
    "        # 1. 안전 장치: 1차원 배열(Bias, Scale 등)은 건너뛰고, \n",
    "        #    다차원 배열(Conv/Linear Weights)만 프루닝하는 것이 일반적입니다.\n",
    "        if weight_array.ndim < 2:\n",
    "            continue\n",
    "            \n",
    "        # 2. 노트북의 프루닝 로직 적용\n",
    "        # (flatten -> 절대값 기준 정렬 -> 하위 k% 인덱스 추출 -> 0으로 설정)\n",
    "        layer_copy = weight_array.flatten()\n",
    "        \n",
    "        # 절대값이 작은 순서대로 정렬하여 인덱스 추출\n",
    "        indices = np.abs(layer_copy).argsort()\n",
    "        \n",
    "        # 하위 k%에 해당하는 개수 계산\n",
    "        n_prune = int(len(indices) * k)\n",
    "        \n",
    "        # 해당 인덱스들을 0으로 설정\n",
    "        indices_to_zero = indices[:n_prune]\n",
    "        layer_copy[indices_to_zero] = 0\n",
    "        \n",
    "        # 3. 변경된 Numpy 배열을 다시 원래 형태(Shape)로 복구\n",
    "        pruned_weight = layer_copy.reshape(weight_array.shape)\n",
    "        \n",
    "        # 4. ONNX Tensor 업데이트\n",
    "        # 기존 데이터를 대체하기 위해 새로운 Tensor 생성\n",
    "        new_tensor = numpy_helper.from_array(pruned_weight, tensor.name)\n",
    "        \n",
    "        # 리스트 내의 해당 텐서를 교체 (직접 할당 불가하므로 copy 및 replace 방식 사용)\n",
    "        model.graph.initializer.remove(tensor)\n",
    "        model.graph.initializer.append(new_tensor)\n",
    "\n",
    "    print(\"Pruning Complete.\")\n",
    "    return model\n",
    "\n",
    "def apply_fp16(model):\n",
    "    \"\"\"\n",
    "    ONNX 모델을 FP16(Half Precision)으로 변환합니다.\n",
    "    \"\"\"\n",
    "    print(\"Converting to FP16...\")\n",
    "    fp16_model = float16.convert_float_to_float16(model)\n",
    "    print(\"FP16 Conversion Complete.\")\n",
    "    return fp16_model\n",
    "\n",
    "# --- 메인 실행 코드 ---\n",
    "if __name__ == \"__main__\":\n",
    "    input_model_path = \"best6.onnx\"\n",
    "    output_model_path = \"best6_pruned_fp16.onnx\"\n",
    "    sparsity_level = 0.2  # 예제 노트북과 같이 20% 희소성 적용 (필요시 조절)\n",
    "\n",
    "    # 1. 모델 로드\n",
    "    print(f\"Loading {input_model_path}...\")\n",
    "    model = onnx.load(input_model_path)\n",
    "\n",
    "    # 2. 프루닝 적용 (노트북 로직)\n",
    "    model = sparsify_onnx_weights(model, k=sparsity_level)\n",
    "\n",
    "    # 3. FP16 변환 적용\n",
    "    model = apply_fp16(model)\n",
    "\n",
    "    # 4. 저장\n",
    "    onnx.save(model, output_model_path)\n",
    "    print(f\"Saved processed model to {output_model_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
