import cv2
import numpy as np
import onnxruntime as ort
import sys
from PIL import Image, ImageDraw, ImageFont

# ==========================================
# [ì„¤ì •]
ONNX_MODEL_PATH = "hanja_yolo3/best6.onnx"
LABEL_PATH      = "./hanja_yolo3/classes.txt"
INPUT_SIZE      = 640
CONF_THRESH     = 0.4
FONT_PATH       = "/usr/share/fonts/truetype/wqy/wqy-microhei.ttc"
# ==========================================

def gstreamer_pipeline(sensor_id=0, capture_width=1280, capture_height=720, display_width=640, display_height=640, framerate=30, flip_method=0):
    # ì•ˆì •ì ì¸ ê¸°ë³¸ íŒŒì´í”„ë¼ì¸ ì‚¬ìš©
    return (
        "nvarguscamerasrc sensor-id=%d ! "
        "video/x-raw(memory:NVMM), width=(int)%d, height=(int)%d, format=(string)NV12, framerate=(fraction)%d/1 ! "
        "nvvidconv flip-method=%d ! "
        "video/x-raw, width=(int)%d, height=(int)%d, format=(string)BGRx ! "
        "videoconvert ! "
        "video/x-raw, format=(string)BGR ! appsink"
        % (sensor_id, capture_width, capture_height, framerate, flip_method, display_width, display_height)
    )

def main():
    # 1. í´ë˜ìŠ¤ ë¡œë“œ
    try:
        with open(LABEL_PATH, "r", encoding="utf-8") as f:
            classes = [line.strip() for line in f.readlines()]
    except:
        print("âš ï¸ classes.txtë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        classes = []

    # 2. í°íŠ¸ ë¡œë“œ
    try:
        font = ImageFont.truetype(FONT_PATH, 30)
    except:
        font = ImageFont.load_default()

    # 3. ëª¨ë¸ ë¡œë“œ
    print(f"ğŸš€ ONNX ëª¨ë¸ ë¡œë”© ì¤‘: {ONNX_MODEL_PATH}")
    providers = ['CUDAExecutionProvider', 'CPUExecutionProvider']
    try:
        session = ort.InferenceSession(ONNX_MODEL_PATH, providers=providers)
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return

    input_name = session.get_inputs()[0].name
    output_name = session.get_outputs()[0].name
    print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")

    # 4. ì¹´ë©”ë¼ ì—°ê²°
    cap = cv2.VideoCapture(gstreamer_pipeline(), cv2.CAP_GSTREAMER)
    if not cap.isOpened():
        sys.exit("âŒ ì¹´ë©”ë¼ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    print("ğŸ¥ ì‹¤í–‰ ì‹œì‘! (ì¢…ë£Œ: q)")

    while True:
        ret, frame = cap.read()
        if not ret:
            print("âŒ ì¹´ë©”ë¼ ë°ì´í„° ìˆ˜ì‹  ì‹¤íŒ¨")
            break

        # ------------------------------------------------
        # [ì „ì²˜ë¦¬]
        # ------------------------------------------------
        img = cv2.resize(frame, (INPUT_SIZE, INPUT_SIZE))
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        img = img.transpose((2, 0, 1)).astype(np.float32) / 255.0
        blob = np.expand_dims(img, axis=0)

        # ------------------------------------------------
        # [ì¶”ë¡ ]
        # ------------------------------------------------
        outputs = session.run([output_name], {input_name: blob})[0]

        # ------------------------------------------------
        # [í›„ì²˜ë¦¬] ë°•ìŠ¤ ê·¸ë¦¬ê¸° (ì£¼ì„ í•´ì œë¨)
        # ------------------------------------------------
        predictions = outputs[0]
        
        boxes = []
        scores = []
        class_ids = []

        x_factor = frame.shape[1] / INPUT_SIZE
        y_factor = frame.shape[0] / INPUT_SIZE

        # ì‹ ë¢°ë„ í•„í„°ë§
        conf_mask = predictions[:, 4] > CONF_THRESH
        detections = predictions[conf_mask]

        for det in detections:
            confidence = det[4]
            class_probs = det[5:]
            class_id = np.argmax(class_probs)
            class_score = class_probs[class_id]
            final_score = confidence * class_score
            
            if final_score > CONF_THRESH:
                x, y, w, h = det[0:4]
                left = int((x - 0.5 * w) * x_factor)
                top = int((y - 0.5 * h) * y_factor)
                width = int(w * x_factor)
                height = int(h * y_factor)

                boxes.append([left, top, width, height])
                scores.append(float(final_score))
                class_ids.append(int(class_id))

        # NMS (ê²¹ì¹œ ë°•ìŠ¤ ì œê±°)
        indices = cv2.dnn.NMSBoxes(boxes, scores, CONF_THRESH, 0.45)

        # í™”ë©´ì— ê·¸ë¦¬ê¸°
        if len(indices) > 0:
            # í•œì ì¶œë ¥ì„ ìœ„í•´ PILë¡œ ë³€í™˜
            img_pil = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
            draw = ImageDraw.Draw(img_pil)
            
            for i in indices:
                idx = i if isinstance(i, int) else i[0]
                box = boxes[idx]
                left, top, w, h = box[0], box[1], box[2], box[3]
                
                # ë¼ë²¨ í…ìŠ¤íŠ¸
                if class_ids[idx] < len(classes):
                    label = f"{classes[class_ids[idx]]} {scores[idx]:.2f}"
                else:
                    label = f"ID:{class_ids[idx]} {scores[idx]:.2f}"

                # ë°•ìŠ¤ì™€ ê¸€ì”¨ ê·¸ë¦¬ê¸°
                draw.rectangle([left, top, left+w, top+h], outline=(0, 255, 0), width=3)
                draw.text((left, top - 30), label, font=font, fill=(0, 255, 0))
            
            # ë‹¤ì‹œ OpenCV í¬ë§·ìœ¼ë¡œ ë³€í™˜
            frame = cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)

        # ------------------------------------------------
        
        cv2.imshow("Hanja Detection", frame)
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    cap.release()
    cv2.destroyAllWindows()

if __name__ == '__main__':
    main()