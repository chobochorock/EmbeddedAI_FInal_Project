{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using LMs for Various NLP Tasks\n",
    "This code demonstrates how to use a language model for text generation, summarization, question answering, machine translation and text classification using in-context learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "model_name = \"google/flan-t5-small\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(prompt, max_length=256):\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
    "\n",
    "    outputs = model.generate(input_ids, max_new_tokens=max_length)\n",
    "    \n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "def print_prompt_response(prompt, response):\n",
    "    border = \"#\" * 30\n",
    "    print(f\"{border}\\n#####  Prompt  #####\\n{border}\")\n",
    "    print(f\"{prompt}\\n\")\n",
    "    print(f\"{border}\\n##### Response #####\\n{border}\")\n",
    "    print(f\"{response}\\n{border}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Example Usage on Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################\n",
      "#####  Prompt  #####\n",
      "##############################\n",
      "Explain about iphone.\n",
      "\n",
      "##############################\n",
      "##### Response #####\n",
      "##############################\n",
      "The iPhone is a mobile phone that can be used to call and text.\n",
      "##############################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Explain about iphone.\"\n",
    "generated_text = generate_text(prompt)\n",
    "\n",
    "print_prompt_response(prompt, generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Example Usage on Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################\n",
      "#####  Prompt  #####\n",
      "##############################\n",
      "Summarize: A new study shows that drinking coffee may reduce the risk of heart disease. Researchers found that people who drink two to three cups of coffee per day have a lower chance of developing heart-related issues compared to non-coffee drinkers. The study suggests that antioxidants in coffee might be responsible for this health benefit.\n",
      "\n",
      "##############################\n",
      "##### Response #####\n",
      "##############################\n",
      "Coffee consumption may help people with heart disease, according to researchers.\n",
      "##############################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def summarize_text(document, max_length=128):\n",
    "    prompt = f\"Summarize: {document}\"\n",
    "    return prompt, generate_text(prompt, max_length=max_length)\n",
    "\n",
    "long_text = '''A new study shows that drinking coffee may reduce the risk of heart disease. Researchers found that people who drink two to three cups of coffee per day have a lower chance of developing heart-related issues compared to non-coffee drinkers. The study suggests that antioxidants in coffee might be responsible for this health benefit.'''\n",
    "input_prompt, summary = summarize_text(long_text)\n",
    "print_prompt_response(input_prompt, summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Example Usage on Question Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################\n",
      "#####  Prompt  #####\n",
      "##############################\n",
      "Context: Marie Curie was a physicist and chemist who conducted pioneering research on radioactivity. She was the first woman to win a Nobel Prize and remains the only person to win Nobel Prizes in two different scientific fields—Physics and Chemistry. Her work led to important developments in the field of medical radiology.\n",
      "Question: In which fields did Marie Curie win Nobel Prizes?\n",
      "Answer:\n",
      "\n",
      "##############################\n",
      "##### Response #####\n",
      "##############################\n",
      "Physics and Chemistry\n",
      "##############################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def answer_question(context, question):\n",
    "    prompt = f\"Context: {context}\\nQuestion: {question}\\nAnswer:\"\n",
    "    return prompt, generate_text(prompt, max_length=50)\n",
    "\n",
    "context = '''Marie Curie was a physicist and chemist who conducted pioneering research on radioactivity. She was the first woman to win a Nobel Prize and remains the only person to win Nobel Prizes in two different scientific fields—Physics and Chemistry. Her work led to important developments in the field of medical radiology.'''\n",
    "question = \"In which fields did Marie Curie win Nobel Prizes?\"\n",
    "input_prompt, answer = answer_question(context, question)\n",
    "\n",
    "print_prompt_response(input_prompt, answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Example Usage on Machine Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################\n",
      "#####  Prompt  #####\n",
      "##############################\n",
      "translate English to German:\n",
      "\n",
      "Thank you very much\n",
      "\n",
      "##############################\n",
      "##### Response #####\n",
      "##############################\n",
      "Danke sehr viel.\n",
      "##############################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def translate_text(text, source_lang=\"English\", target_lang=\"German\"):\n",
    "    prompt = f\"translate {source_lang} to {target_lang}:\\n\\n\"\n",
    "    prompt += f\"{text}\"\n",
    "    return prompt, generate_text(prompt, max_length=128).strip()\n",
    "\n",
    "text_to_translate = \"Thank you very much\"\n",
    "input_prompt, translation = translate_text(text_to_translate)\n",
    "print_prompt_response(input_prompt, translation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Example Usage on In-context Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################\n",
      "#####  Prompt  #####\n",
      "##############################\n",
      "Text Classification:\n",
      "\n",
      "Text: I loved the movie; it was amazing!\n",
      "Label: Positive\n",
      "\n",
      "Text: The film was dull and too long.\n",
      "Label: Negative\n",
      "\n",
      "Text: Fantastic plot and great acting.\n",
      "Label: Positive\n",
      "\n",
      "Text: The storyline was boring and predictable.\n",
      "Label:\n",
      "\n",
      "##############################\n",
      "##### Response #####\n",
      "##############################\n",
      "Negative\n",
      "##############################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def classify_text(text, examples, labels):\n",
    "    prompt = \"Text Classification:\\n\\n\"\n",
    "    for ex, label in zip(examples, labels):\n",
    "        prompt += f\"Text: {ex}\\nLabel: {label}\\n\\n\"\n",
    "    prompt += f\"Text: {text}\\nLabel:\"\n",
    "    return prompt, generate_text(prompt, max_length=10)\n",
    "\n",
    "examples = [\n",
    "    \"I loved the movie; it was amazing!\",\n",
    "    \"The film was dull and too long.\",\n",
    "    \"Fantastic plot and great acting.\"\n",
    "]\n",
    "labels = [\"Positive\", \"Negative\", \"Positive\"]\n",
    "text_to_classify = \"The storyline was boring and predictable.\"\n",
    "input_prompt, classification = classify_text(text_to_classify, examples, labels)\n",
    "print_prompt_response(input_prompt, classification)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
